{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 병합 결과: (26099, 27)\n",
      "테스트 데이터 병합 결과: (6525, 26)\n",
      "병합된 데이터가 TRAIN_DATA_ver2.csv와 TEST_DATA_ver2.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "## 1-2. 지역별 그룹핑 + 폐지된건 개칭된걸로 변경\n",
    "\n",
    "# 필요한 패키지 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sido_code_map = {\n",
    "    '11': '서울특별시',\n",
    "    '26': '부산광역시',\n",
    "    '27': '대구광역시',\n",
    "    '28': '인천광역시',\n",
    "    '29': '광주광역시',\n",
    "    '30': '대전광역시',\n",
    "    '31': '울산광역시',\n",
    "    '36': '세종특별자치시',\n",
    "    '41': '경기도',\n",
    "    '42': '강원특별자치도',               # 폐지\n",
    "    '43': '충청북도',\n",
    "    '44': '충청남도',\n",
    "    '45': '전북특별자치도',             # 폐지\n",
    "    '46': '전라남도',\n",
    "    '47': '경상북도',\n",
    "    '48': '경상남도',\n",
    "    '49': '제주특별자치도',              # 폐지, 데이터 내 미존재\n",
    "    '50': '제주특별자치도',      # 2006년 1월 이후 제주도의 승격·개칭 \n",
    "    '51': '강원특별자치도',      # 2023년 7월 이후 강원도의 승격·개칭 \n",
    "    '52': '전북특별자치도'       # 2023년 7월 이후 전라북도의 승격·개칭\n",
    "}\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_dir = r'C:\\Git_project\\SAS-Korea_Data-Analysis\\SAS-Korea_Data-Analysis\\data'\n",
    "\n",
    "# TRAIN_DATA와 TEST_DATA 로드\n",
    "train_data = pd.read_csv(os.path.join(data_dir, 'TRAIN_DATA.csv'), encoding='cp949')\n",
    "test_data = pd.read_csv(os.path.join(data_dir, 'TEST_DATA.csv'), encoding='cp949')\n",
    "기온_data = pd.read_csv(os.path.join(data_dir, '기온real.csv'))  # 기온 데이터 로드\n",
    "\n",
    "# 지역 코드 전처리 및 지역명 매핑 - 훈련 데이터\n",
    "train_data['DIST_CD1'] = train_data['DIST_CD'].astype(str).str[:2]\n",
    "train_data['SIDO_NM'] = train_data['DIST_CD1'].map(sido_code_map)\n",
    "\n",
    "# 지역 코드 전처리 및 지역명 매핑 - 테스트 데이터\n",
    "test_data['DIST_CD1'] = test_data['DIST_CD'].astype(str).str[:2]\n",
    "test_data['SIDO_NM'] = test_data['DIST_CD1'].map(sido_code_map)\n",
    "\n",
    "# 기온 데이터 전처리\n",
    "기온_data['DATA_YM'] = pd.to_datetime(기온_data['DATA_YM']).dt.strftime('%Y%m')\n",
    "\n",
    "# 날짜 타입 통일\n",
    "train_data['DATA_YM'] = train_data['DATA_YM'].astype(str)\n",
    "test_data['DATA_YM'] = test_data['DATA_YM'].astype(str)\n",
    "기온_data['DATA_YM'] = 기온_data['DATA_YM'].astype(str)\n",
    "\n",
    "# 공백 제거\n",
    "train_data['SIDO_NM'] = train_data['SIDO_NM'].str.strip()\n",
    "test_data['SIDO_NM'] = test_data['SIDO_NM'].str.strip()\n",
    "기온_data['SIDO_NM'] = 기온_data['SIDO_NM'].str.strip()\n",
    "\n",
    "# 병합 - 훈련 데이터\n",
    "train_merged = pd.merge(train_data, 기온_data, on=['DATA_YM', 'SIDO_NM'], how='left')\n",
    "\n",
    "# 병합 - 테스트 데이터\n",
    "test_merged = pd.merge(test_data, 기온_data, on=['DATA_YM', 'SIDO_NM'], how='left')\n",
    "\n",
    "# DIST_CD1과 SIDO_NM 컬럼 제거\n",
    "train_merged = train_merged.drop(['DIST_CD1', 'SIDO_NM'], axis=1)\n",
    "test_merged = test_merged.drop(['DIST_CD1', 'SIDO_NM'], axis=1)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"훈련 데이터 병합 결과: {train_merged.shape}\")\n",
    "print(f\"테스트 데이터 병합 결과: {test_merged.shape}\")\n",
    "\n",
    "# 병합된 데이터를 CSV 파일로 저장\n",
    "train_merged.to_csv(os.path.join(data_dir, 'TRAIN_DATA_ver2.csv'), index=False, encoding='cp949')\n",
    "test_merged.to_csv(os.path.join(data_dir, 'TEST_DATA_ver2.csv'), index=False, encoding='cp949')\n",
    "\n",
    "print(\"병합된 데이터가 TRAIN_DATA_ver2.csv와 TEST_DATA_ver2.csv로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 병합 전 훈련 데이터 크기: (26099, 27)\n",
      "PCA 병합 전 테스트 데이터 크기: (6525, 26)\n",
      "PCA 병합 후 훈련 데이터 크기: (32041, 30)\n",
      "PCA 병합 후 테스트 데이터 크기: (6962, 29)\n",
      "\n",
      "PCA 변수 결측치 확인 - 병합 직후:\n",
      "훈련 데이터: PC1        4\n",
      "PC2        4\n",
      "CLUSTER    4\n",
      "dtype: int64\n",
      "테스트 데이터: PC1        5102\n",
      "PC2        5102\n",
      "CLUSTER    5102\n",
      "dtype: int64\n",
      "\n",
      "PCA 변수 결측치 확인 - AREA_ID별 평균/최빈값으로 채운 후:\n",
      "훈련 데이터: PC1        0\n",
      "PC2        0\n",
      "CLUSTER    0\n",
      "dtype: int64\n",
      "테스트 데이터: PC1        0\n",
      "PC2        0\n",
      "CLUSTER    0\n",
      "dtype: int64\n",
      "\n",
      "PCA 변수가 추가된 데이터가 TRAIN_DATA_ver3.csv와 TEST_DATA_ver3.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# PCA 데이터 로드\n",
    "pca_data = pd.read_csv(os.path.join(data_dir, 'pca.csv'))\n",
    "\n",
    "# PCA 데이터의 DATA_YM 형식 변환 (date 형식 -> 'YYYYMM' 형식)\n",
    "if pd.api.types.is_datetime64_any_dtype(pca_data['DATA_YM']):\n",
    "    # 날짜 형식인 경우 YYYYMM 형식으로 변환\n",
    "    pca_data['DATA_YM'] = pd.to_datetime(pca_data['DATA_YM']).dt.strftime('%Y%m')\n",
    "else:\n",
    "    # 이미 문자열인 경우 형식 확인 후 필요시 변환\n",
    "    try:\n",
    "        pca_data['DATA_YM'] = pd.to_datetime(pca_data['DATA_YM']).dt.strftime('%Y%m')\n",
    "    except:\n",
    "        print(\"DATA_YM 형식 변환 중 오류가 발생했습니다. 형식을 확인해주세요.\")\n",
    "\n",
    "# 데이터 타입 통일\n",
    "pca_data['DATA_YM'] = pca_data['DATA_YM'].astype(str)\n",
    "pca_data['AREA_ID'] = pca_data['AREA_ID'].astype(str)\n",
    "\n",
    "# TRAIN_DATA_ver2와 TEST_DATA_ver2 다시 로드\n",
    "train_ver2 = pd.read_csv(os.path.join(data_dir, 'TRAIN_DATA_ver2.csv'), encoding='cp949')\n",
    "test_ver2 = pd.read_csv(os.path.join(data_dir, 'TEST_DATA_ver2.csv'), encoding='cp949')\n",
    "\n",
    "# 데이터 타입 통일\n",
    "train_ver2['DATA_YM'] = train_ver2['DATA_YM'].astype(str)\n",
    "train_ver2['AREA_ID'] = train_ver2['AREA_ID'].astype(str)\n",
    "test_ver2['DATA_YM'] = test_ver2['DATA_YM'].astype(str)\n",
    "test_ver2['AREA_ID'] = test_ver2['AREA_ID'].astype(str)\n",
    "\n",
    "# PCA 데이터에서 필요한 컬럼만 선택\n",
    "pca_selected = pca_data[['AREA_ID', 'DATA_YM', 'PC1', 'PC2', 'CLUSTER']]\n",
    "\n",
    "# 병합 - 훈련 데이터\n",
    "train_ver2_pca = pd.merge(train_ver2, pca_selected, on=['AREA_ID', 'DATA_YM'], how='left')\n",
    "\n",
    "# 병합 - 테스트 데이터\n",
    "test_ver2_pca = pd.merge(test_ver2, pca_selected, on=['AREA_ID', 'DATA_YM'], how='left')\n",
    "\n",
    "# 결측치 확인 (병합 전)\n",
    "print(f\"PCA 병합 전 훈련 데이터 크기: {train_ver2.shape}\")\n",
    "print(f\"PCA 병합 전 테스트 데이터 크기: {test_ver2.shape}\")\n",
    "\n",
    "# 결측치 확인 (병합 후)\n",
    "print(f\"PCA 병합 후 훈련 데이터 크기: {train_ver2_pca.shape}\")\n",
    "print(f\"PCA 병합 후 테스트 데이터 크기: {test_ver2_pca.shape}\")\n",
    "\n",
    "print(\"\\nPCA 변수 결측치 확인 - 병합 직후:\")\n",
    "print(\"훈련 데이터:\", train_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "print(\"테스트 데이터:\", test_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "\n",
    "# AREA_ID별 평균값 계산\n",
    "pca_means = pca_data.groupby('AREA_ID')[['PC1', 'PC2']].mean().reset_index()\n",
    "# CLUSTER는 범주형이므로 최빈값 사용\n",
    "pca_mode = pca_data.groupby('AREA_ID')['CLUSTER'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "# 결측치 채우기 - 훈련 데이터\n",
    "for idx, row in train_ver2_pca[train_ver2_pca['PC1'].isnull()].iterrows():\n",
    "    area_id = row['AREA_ID']\n",
    "    # PC1, PC2 평균값으로 채우기\n",
    "    if area_id in pca_means['AREA_ID'].values:\n",
    "        mean_values = pca_means[pca_means['AREA_ID'] == area_id].iloc[0]\n",
    "        train_ver2_pca.at[idx, 'PC1'] = mean_values['PC1']\n",
    "        train_ver2_pca.at[idx, 'PC2'] = mean_values['PC2']\n",
    "    \n",
    "    # CLUSTER 최빈값으로 채우기\n",
    "    if area_id in pca_mode['AREA_ID'].values:\n",
    "        mode_value = pca_mode[pca_mode['AREA_ID'] == area_id].iloc[0]['CLUSTER']\n",
    "        train_ver2_pca.at[idx, 'CLUSTER'] = mode_value\n",
    "\n",
    "# 결측치 채우기 - 테스트 데이터\n",
    "for idx, row in test_ver2_pca[test_ver2_pca['PC1'].isnull()].iterrows():\n",
    "    area_id = row['AREA_ID']\n",
    "    # PC1, PC2 평균값으로 채우기\n",
    "    if area_id in pca_means['AREA_ID'].values:\n",
    "        mean_values = pca_means[pca_means['AREA_ID'] == area_id].iloc[0]\n",
    "        test_ver2_pca.at[idx, 'PC1'] = mean_values['PC1']\n",
    "        test_ver2_pca.at[idx, 'PC2'] = mean_values['PC2']\n",
    "    \n",
    "    # CLUSTER 최빈값으로 채우기\n",
    "    if area_id in pca_mode['AREA_ID'].values:\n",
    "        mode_value = pca_mode[pca_mode['AREA_ID'] == area_id].iloc[0]['CLUSTER']\n",
    "        test_ver2_pca.at[idx, 'CLUSTER'] = mode_value\n",
    "\n",
    "# 결측치 확인 (채운 후)\n",
    "print(\"\\nPCA 변수 결측치 확인 - AREA_ID별 평균/최빈값으로 채운 후:\")\n",
    "print(\"훈련 데이터:\", train_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "print(\"테스트 데이터:\", test_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "\n",
    "# 여전히 남아있는 결측치가 있다면 전체 평균/최빈값으로 채우기\n",
    "if train_ver2_pca['PC1'].isnull().sum() > 0 or test_ver2_pca['PC1'].isnull().sum() > 0:\n",
    "    # 전체 평균 계산\n",
    "    total_pc1_mean = pca_data['PC1'].mean()\n",
    "    total_pc2_mean = pca_data['PC2'].mean()\n",
    "    total_cluster_mode = pca_data['CLUSTER'].mode()[0]\n",
    "    \n",
    "    # 남은 결측치 채우기\n",
    "    train_ver2_pca['PC1'].fillna(total_pc1_mean, inplace=True)\n",
    "    train_ver2_pca['PC2'].fillna(total_pc2_mean, inplace=True)\n",
    "    train_ver2_pca['CLUSTER'].fillna(total_cluster_mode, inplace=True)\n",
    "    \n",
    "    test_ver2_pca['PC1'].fillna(total_pc1_mean, inplace=True)\n",
    "    test_ver2_pca['PC2'].fillna(total_pc2_mean, inplace=True)\n",
    "    test_ver2_pca['CLUSTER'].fillna(total_cluster_mode, inplace=True)\n",
    "    \n",
    "    print(\"\\nPCA 변수 결측치 확인 - 전체 평균/최빈값으로 채운 후:\")\n",
    "    print(\"훈련 데이터:\", train_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "    print(\"테스트 데이터:\", test_ver2_pca[['PC1', 'PC2', 'CLUSTER']].isnull().sum())\n",
    "\n",
    "# 병합된 데이터를 CSV 파일로 저장\n",
    "train_ver2_pca.to_csv(os.path.join(data_dir, 'TRAIN_DATA_ver4.csv'), index=False, encoding='cp949')\n",
    "test_ver2_pca.to_csv(os.path.join(data_dir, 'TEST_DATA_ver4.csv'), index=False, encoding='cp949')\n",
    "\n",
    "print(\"\\nPCA 변수가 추가된 데이터가 TRAIN_DATA_ver3.csv와 TEST_DATA_ver3.csv로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
